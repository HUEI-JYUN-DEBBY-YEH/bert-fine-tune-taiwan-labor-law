import os
import json
import re

def preprocess_laborlaw_text(raw_text):
    # åˆ‡å¥ï¼šä¾æ“šæ¯ä¸€æ¢æ¢æ–‡ç‚ºå–®ä½
    raw_sentences = re.split(r'\n|ç¬¬\d+æ¢', raw_text)
    sentences = [s.strip() for s in raw_sentences if s.strip()]
    dataset = [{"id": i + 1, "text": sentence, "label": ""} for i, sentence in enumerate(sentences)]
    return dataset

def batch_process_txt_files(input_dir, output_path):
    all_sentences = []
    file_count = 0

    for filename in os.listdir(input_dir):
        if filename.endswith(".txt"):
            file_path = os.path.join(input_dir, filename)
            with open(file_path, "r", encoding="utf-8") as f:
                raw_text = f.read()
            processed = preprocess_laborlaw_text(raw_text)
            all_sentences.extend(processed)
            file_count += 1

    print(f"âœ… è™•ç†å®Œæˆï¼Œå…±è®€å– {file_count} å€‹æª”æ¡ˆï¼Œè¼¸å‡º {len(all_sentences)} æ¢å¥å­ã€‚")
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(all_sentences, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    # ğŸ—‚ï¸ è¨­å®šè¼¸å…¥è³‡æ–™å¤¾èˆ‡è¼¸å‡ºè·¯å¾‘
    input_folder = "raw_laborlaw_txt"
    output_file = "laborlaw_sentences_unlabeled.json"

    # ğŸš€ åŸ·è¡Œæ‰¹æ¬¡è™•ç†
    batch_process_txt_files(input_folder, output_file)
